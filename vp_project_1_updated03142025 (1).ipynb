{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJG_e1vK2NMI"
      },
      "source": [
        "# Project Title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugnt7mjT2Pyt"
      },
      "source": [
        "## Problem Definition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJB41zc-2q-w"
      },
      "source": [
        "State the business problem. Translate the business problem into a Data Science problem by stating what kind of problem it is ( supervised vs unsupervised ) and whether it is a classification, regression, or clustering problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoFXZHdexsUj"
      },
      "source": [
        " Business Problem\n",
        "\n",
        "*   We want to know whether or not a future customer will make a transaction based on their previous transactions.\n",
        "*  This is a supervised problem because we have labeled data (wheter or not the customer made the transaction in 0 or 1)\n",
        "*  This is a classification problem because we are classifying into two categories (1 is a succesful transaction, 0 is unsuccesful)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaq46wHS2Uh1"
      },
      "source": [
        "## Data Collection/Sources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z8xlropzguWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Pandas, Numpy, and Matplotlib.."
      ],
      "metadata": {
        "id": "ZH6cknVbg_Tj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNOARr9i2qW8"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from sklearn import datasets, metrics, model_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data Train.csv from the Google Drive folder."
      ],
      "metadata": {
        "id": "bj--SVP5hB4d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii6VQ02NwFoa"
      },
      "outputs": [],
      "source": [
        "# First I will assign my file path a name\n",
        "url = 'https://ddc-datascience.s3.amazonaws.com/Projects/Project.1-Transactions/Data/Transaction.train.csv'\n",
        "# I am assigning a variable to the read_csv function to read a CSV file in a pandas dataframe\n",
        "df = pd.read_csv(url)\n",
        "# using the .head function I am looking at the first 5 rows of the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvTak8Ka2db2"
      },
      "source": [
        "## Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k4Q6cbo42paj"
      },
      "outputs": [],
      "source": [
        "# using .info to look at a general summary in the dataframe\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJGmS73HxPz9"
      },
      "outputs": [],
      "source": [
        "# using .describe to look at common statistcal info of the data\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOx1ePZExR2P"
      },
      "outputs": [],
      "source": [
        "# .shape gives info of (rows, columns)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6lOjwIhxg6I"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lu0akvfj0-7n"
      },
      "outputs": [],
      "source": [
        "# using .copy allows me to make a new object with the data in the original dataframe without changing original dataframe\n",
        "df_new = df.copy()\n",
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guPZG6ZJ1lJp"
      },
      "outputs": [],
      "source": [
        "# Checking to see if the copy looks correct\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osA7Pf7z3I3k"
      },
      "outputs": [],
      "source": [
        "# Dropping unnamed column because it just is number of rows from 0-180000\n",
        "df_new.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muebXtxE3NgZ"
      },
      "outputs": [],
      "source": [
        "# Also dropping ID_code because it gives same info as counting down the rows\n",
        "df_new.drop(['ID_code'], axis=1, inplace=True)\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX_4Erkb3-kj"
      },
      "outputs": [],
      "source": [
        "# Column 'target' has values of either 0 or 1 based on the .info\n",
        "# to make sure we still need this row I will look at the data\n",
        "df_new['target'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCvajwjM6RCB"
      },
      "outputs": [],
      "source": [
        "#I will keep this row because it does have a value of 0 or 1 assigned to each row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc1iOqdg6g6q",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Check presence of nulls\n",
        "df_new.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mimAdbCq63xc"
      },
      "outputs": [],
      "source": [
        "# We have no nulls so we can move on from the data cleaning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvh5r9Zs2fkc"
      },
      "source": [
        "## Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = df_new.drop(columns=['target'])  # Remove the target column\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = predictors.corr()\n",
        "\n",
        "# Plot the heatmap for visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title('Correlation Matrix of Predictor Variables')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SXTmXQ_VaQ4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows us that all of the values have a correlation value of nearly 0, which means that there is no correlation between the variables. This is great for a Naive Bayes because it assumes independence of variables."
      ],
      "metadata": {
        "id": "yPhFHkr9bBM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Efloab12ouN"
      },
      "outputs": [],
      "source": [
        "#Here i'm not taking out the target column. This is an issue because i'm not just looking at predictor values.\n",
        "corr = df_new.corr()\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.heatmap(corr, cmap='RdYlBu',annot = False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2ag_BBvBvsR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for col in df_new.columns:\n",
        "    print(col)\n",
        "    print(df_new[col].unique())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for plot in df_new.columns: # Looking at distribution of all variables\n",
        "    fig = px.histogram(df_new, x=plot, color='target')\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9aisHfIvDodP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for plot in df_new.columns:\n",
        "    fig = px.box(df_new, x='target', y=plot)\n",
        "    fig.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RGtdIrFPEp1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Creating two data frames, one with succesful transactions, one with unsuccesful transactions."
      ],
      "metadata": {
        "id": "9qeDOViGbwbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Successful transactions (target == 1)\n",
        "successful_transactions = df[df['target'] == 1].copy()\n",
        "\n",
        "# Unsuccessful transactions (target == 0)\n",
        "unsuccessful_transactions = df[df['target'] == 0].copy()"
      ],
      "metadata": {
        "id": "1HjubhG6bumA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making sure the copy worked by checking original dataframe\n",
        "print(df.head())  # Original DataFrame should remain unchanged"
      ],
      "metadata": {
        "id": "HBeuJ_U-b9YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij_fgEbh2hVk"
      },
      "source": [
        "## Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create two data frames: one with all the predictor columns (everything except for Unnamed: 0, ID_code and target) and one with just the target. Make sure they are copies and not slices."
      ],
      "metadata": {
        "id": "vYfpKhuKh1TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the predictors DataFrame (excluding 'Unnamed: 0', 'ID_code', and 'target')\n",
        "predictors = df.drop(columns=['Unnamed: 0', 'ID_code', 'target']).copy()\n",
        "\n",
        "# Create the target DataFrame (just the 'target' column)\n",
        "target = df['target'].copy()"
      ],
      "metadata": {
        "id": "lqD62-Rmcm9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gaussian Naïve Bayes model\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "TJUse963WYM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation loop to calculate accuracy of model\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv_scores = cross_val_score(gnb, predictors, target, cv=5, scoring='accuracy')\n",
        "\n",
        "# Calculate the mean accuracy from the cross-validation scores\n",
        "mean_accuracy = np.mean(cv_scores)\n",
        "\n",
        "# Report the cross-validation accuracy\n",
        "print(f\"Cross-Validation Accuracy: {mean_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "RyNRhgRBdtY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-validation accuracy is 91.12%. The cross-validation result is a general estimate of model performance. The accuracy calculated in the previous training model is 90.89%. The difference could be coming from the randomness in the train-test split. The cross-validation is averages performance across multiple splits so can be more robust.\n"
      ],
      "metadata": {
        "id": "czZWCdiGeJyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot histogram of the accuracy scores in cross-validation loop\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(cv_scores, bins=5, edgecolor='black', color = 'green', alpha=0.7)  # Customize number of bins\n",
        "plt.title(\"Histogram of Cross-Validation Accuracy Scores\")\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "print(\"Cross-validation accuracy scores: \", cv_scores)"
      ],
      "metadata": {
        "id": "yjNMxL8WeZXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"0\", \"1\"], yticklabels=[\"0\", \"1\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Unsuccesful vs Succesful\")\n",
        "plt.ylabel(\"Unsuccesful vs Succesful\")\n",
        "plt.show()\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "MPDTesygeY-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the successful (target == 1) and unsuccessful (target == 0) transactions\n",
        "successful_transactions = df[df['target'] == 1]\n",
        "unsuccessful_transactions = df[df['target'] == 0]\n",
        "\n",
        "# Determine the number of non-successful rows to keep\n",
        "num_successful = len(successful_transactions)\n",
        "num_unsuccessful_to_keep = num_successful  # We want a 50/50 split\n",
        "\n",
        "# Randomly sample the non-successful transactions\n",
        "unsuccessful_transactions_sampled = unsuccessful_transactions.sample(n=num_unsuccessful_to_keep, random_state=42)\n",
        "\n",
        "# Combine the successful and non-successful transactions to form the balanced dataset\n",
        "balanced_df = pd.concat([successful_transactions, unsuccessful_transactions_sampled])\n",
        "\n",
        "# Shuffle the combined dataset to mix the rows of successful and non-successful transactions\n",
        "balanced_df_x = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# balanced_df has a 50/50 split between successful and non-successful transactions\n",
        "print(f\"Balanced dataset shape: {balanced_df_x.shape}\")\n",
        "\n",
        "# Create the predictors DataFrame (excluding 'Unnamed: 0', 'ID_code', and 'target')\n",
        "predictors_b = balanced_df_x.drop(columns=['Unnamed: 0', 'ID_code', 'target']).copy()\n",
        "\n",
        "# Create the target DataFrame (just the 'target' column)\n",
        "target_b = balanced_df_x['target'].copy()\n",
        "\n",
        "balanced_df_x.head()"
      ],
      "metadata": {
        "id": "H0M9eKntffxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(predictors_b, target_b, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gaussian Naïve Bayes model\n",
        "gnb_b = GaussianNB()\n",
        "gnb_b.fit(X_train_b, y_train_b)\n",
        "y_pred_b = gnb_b.predict(X_test_b)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test_b, y_pred_b)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "hKzKpCB9maiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "# Generate confusion matrix\n",
        "confusion_matrix_b = metrics.confusion_matrix(y_test_b, y_pred_b)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(confusion_matrix_b, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Successful (0)', 'Successful (1)'], yticklabels=['Non-Successful (0)', 'Successful (1)'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Unsuccesful vs Succesful')\n",
        "plt.ylabel('Unsuccesful vs Succesful')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l0swUABkqfnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_b = metrics.confusion_matrix(y_test_b, y_pred_b)\n",
        "print(confusion_matrix_b)"
      ],
      "metadata": {
        "id": "fU0LPlzWkQaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_balanced = balanced_df_x.drop(columns=['Unnamed: 0', 'ID_code', 'target'])  # Exclude the target column and other irrelevant columns\n",
        "y_balanced = balanced_df_x['target']\n",
        "\n",
        "gnb_b = GaussianNB()\n",
        "cv_scores = cross_val_score(gnb_b, X_balanced, y_balanced, cv=5, scoring='accuracy')\n",
        "\n",
        "# Calculate the mean accuracy from the cross-validation scores\n",
        "mean_accuracy = np.mean(cv_scores)\n",
        "\n",
        "# Report the cross-validation accuracy\n",
        "print(f\"Cross-Validation Accuracy on 50/50 Split: {mean_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "TeczKWW-fvfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_imbalanced = df.drop(columns=['Unnamed: 0', 'ID_code', 'target'])\n",
        "y_imbalanced = df['target']\n",
        "\n",
        "# For balanced data (50/50 split)\n",
        "X_balanced = balanced_df_x.drop(columns=['Unnamed: 0', 'ID_code', 'target'])\n",
        "y_balanced = balanced_df_x['target']\n",
        "\n",
        "# Define the Gaussian Naïve Bayes model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#  Perform cross-validation on the imbalanced training data\n",
        "cv_scores_imbalanced = cross_val_score(gnb, X_imbalanced, y_imbalanced, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform cross-validation on the 50/50 balanced training data\n",
        "cv_scores_balanced = cross_val_score(gnb_b, X_balanced, y_balanced, cv=5, scoring='accuracy')\n",
        "\n",
        "# Calculate and compare the mean accuracy for both\n",
        "mean_accuracy_imbalanced = np.mean(cv_scores_imbalanced)\n",
        "mean_accuracy_balanced = np.mean(cv_scores_balanced)\n",
        "\n",
        "print(f\"Cross-Validation Accuracy on Imbalanced Data: {mean_accuracy_imbalanced * 100:.2f}%\")\n",
        "print(f\"Cross-Validation Accuracy on 50/50 Balanced Data: {mean_accuracy_balanced * 100:.2f}%\")\n",
        "\n",
        "\n",
        "print(f\"Imbalanced Data CV Scores: {cv_scores_imbalanced}\")\n",
        "print(f\"Balanced Data CV Scores: {cv_scores_balanced}\")\n"
      ],
      "metadata": {
        "id": "_BVXUZuQf-le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "report_b = classification_report(y_test_b, y_pred_b)\n",
        "print(\"Classification Report on Balanced Data:\")\n",
        "print(report_b)"
      ],
      "metadata": {
        "id": "om80rAAtgaAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjDTKyc12jR7"
      },
      "source": [
        "## Data Visualization/Communication of Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlNH7PFy2k9-"
      },
      "outputs": [],
      "source": [
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "report_b = classification_report(y_test_b, y_pred_b, output_dict=True)\n",
        "\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report_b = pd.DataFrame(report_b).transpose()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Original dataset\n",
        "sns.barplot(x=df_report.index[:-3], y=df_report['precision'][:-3], ax=axes[0], color='blue', label='Precision')\n",
        "sns.barplot(x=df_report.index[:-3], y=df_report['recall'][:-3], ax=axes[0], color='green', label='Recall')\n",
        "sns.barplot(x=df_report.index[:-3], y=df_report['f1-score'][:-3], ax=axes[0], color='hotpink', label='F1-Score')\n",
        "\n",
        "axes[0].set_title('Classification Report - Original Data')\n",
        "axes[0].set_xlabel('Classes')\n",
        "axes[0].set_ylabel('Scores')\n",
        "axes[0].legend()\n",
        "\n",
        "# Balanced dataset\n",
        "sns.barplot(x=df_report_b.index[:-3], y=df_report_b['precision'][:-3], ax=axes[1], color='blue', label='Precision')\n",
        "sns.barplot(x=df_report_b.index[:-3], y=df_report_b['recall'][:-3], ax=axes[1], color='green', label='Recall')\n",
        "sns.barplot(x=df_report_b.index[:-3], y=df_report_b['f1-score'][:-3], ax=axes[1], color='hotpink', label='F1-Score')\n",
        "\n",
        "axes[1].set_title('Classification Report - Balanced Data')\n",
        "axes[1].set_xlabel('Classes')\n",
        "axes[1].set_ylabel('Scores')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, in the balanced dataset, there is a much better F-1 score for the succesful transactions (1). We can take a better F-1 score to mean that our model is doing a better job in balancing both precison and recall in datasets that are imbalanced. This makes sense, because we acheived a more balanced set by selecting a random sampling of unsuccesful transactions in the balanced sets as the original dataset was skewed toward the unsuccesful transactions. In terns of our business model, we'd better be able to predict if someone will purchase something based on their past transactions."
      ],
      "metadata": {
        "id": "ZZpvcvZDvhfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also want to focus on the succesful transactions instead of the negative ones because that will give us more data as to how to continue to get succesful transactions."
      ],
      "metadata": {
        "id": "YAFnEnRhxTf_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FkBFh_844QGL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}